{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_ids(items_ext):\n",
    "    href = items_ext.getAttribute('href')\n",
    "    filename = href.split('#')[0]\n",
    "    id_tmp = href.split('#')[-1].split(')..id(')\n",
    "    init_id = id_tmp[0].split('id(')[-1].split(')')[0]\n",
    "    final_id = None\n",
    "    if len(id_tmp) > 1:\n",
    "        final_id = id_tmp[1].split(')')[0]\n",
    "    return filename, init_id, final_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_node_from_textname(path, id_arr, tag):\n",
    "    mydoc = minidom.parse(path)\n",
    "    items_dact = mydoc.getElementsByTagName(tag)\n",
    "    nodes = []\n",
    "    for item in items_dact:\n",
    "        nite_id = item.getAttribute('nite:id')\n",
    "        if nite_id in id_arr:\n",
    "            nodes.append(item)\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_dialogue_act_word_references(word_nodes):\n",
    "    \"\"\" Obtain words from word references\n",
    "\n",
    "        :param word_nodes: nodes representing words\n",
    "        :return: string with concatenated words\n",
    "    \"\"\"\n",
    "    words = \"\"\n",
    "\n",
    "    for word_node in word_nodes:\n",
    "        words += word_node.firstChild.data + \" \"\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████▉     | 520/556 [3:14:26<06:42, 11.18s/it]"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "from xml.dom import minidom\n",
    "from os.path import isfile, join\n",
    "mypath=r\"C:\\\\Users\\\\mohan.adabala\\\\Music\\\\ML Pracice\\\\NLP\\\\Document Summarization\\\\AMICorpusXML-master\\\\data\\\\ami_public_manual_1.6.2\\\\dialogueActs\\\\\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "contains=\"adjacency-pairs\"\n",
    "onlyfiles_new=[files for files in onlyfiles if contains not in files]\n",
    "Sent_all=[]\n",
    "Label_all=[]\n",
    "for fil in tqdm(onlyfiles_new):\n",
    "#     print()\n",
    "    dactpath=mypath+fil\n",
    "    mydoc = minidom.parse(dactpath)\n",
    "    items_dact = mydoc.getElementsByTagName('dact')\n",
    "    nodes = []\n",
    "    sentence_segment = []\n",
    "    sum_dir = r\"C:\\\\Users\\\\mohan.adabala\\\\Music\\\\ML Pracice\\\\NLP\\\\Document Summarization\\\\AMICorpusXML-master\\\\data\\\\ami_public_manual_1.6.2\\\\words\\\\\"\n",
    "# nite:pointer\n",
    "    label=[]\n",
    "# items_extsumm=[]\n",
    "    for segment_node in items_dact:\n",
    "            # Obtain child node with words information\n",
    "        for seg in segment_node.childNodes:\n",
    "            if seg.attributes is not None:\n",
    "                if seg.nodeName == 'nite:pointer':\n",
    "                    items_extsumm = seg\n",
    "        filename, init_id, final_id = obtain_ids(items_extsumm)\n",
    "        label.append(init_id)\n",
    "    Label_all.append(label)        \n",
    "# for it in items_dact:\n",
    "    for segment_node in items_dact:\n",
    "            # Obtain child node with words information\n",
    "        for seg in segment_node.childNodes:\n",
    "            if seg.attributes is not None:\n",
    "                if seg.nodeName == 'nite:child':\n",
    "                    items_extsumm = seg  # segment_node.childNodes[3]  # Element\n",
    "\n",
    "        filename, init_id, final_id = obtain_ids(items_extsumm)\n",
    "        id_arr = [init_id]\n",
    "        if final_id is not None:\n",
    "            init_id_index = int(init_id.split('words')[-1])\n",
    "            final_id_index = int(final_id.split('words')[-1])\n",
    "            root_name = final_id.split(str(final_id_index))[0]\n",
    "            for i in range(init_id_index + 1, final_id_index + 1):\n",
    "                id_arr.append(root_name + str(i))\n",
    "        word_nodes = obtain_node_from_textname(sum_dir + filename, id_arr, tag='w')\n",
    "        sentence_segment.append(obtain_dialogue_act_word_references(word_nodes))        \n",
    "    Sent_all.append(sentence_segment)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_sent = [item for sublist in Sent_all for item in sublist]\n",
    "flat_label = [item for sublist in Label_all for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_sent[100],flat_label[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'sentence':  flat_sent,\n",
    "        'label': flat_label\n",
    "        }\n",
    "df = pd.DataFrame (data, columns = ['sentence','label'])\n",
    "print (df)\n",
    "# 5, 11\n",
    "df.to_pickle(\"./sent_annot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "american = df['label'] == \"ami_da_6\"\n",
    "df[american]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
